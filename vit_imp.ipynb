{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3edf506",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch \n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912ccf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b919ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_setup\n",
    "import engine\n",
    "from helper_functions import download_data, set_seeds, plot_loss_curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee30dc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0459c188",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download dataset if none already exists\n",
    "#Dataset is pizza_steak_sushi\n",
    "image_path = download_data(\n",
    "    source=\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\", \n",
    "    destination=\"pizza_steak_sushi\"\n",
    ")\n",
    "image_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff67e411",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set-up test and train paths \n",
    "train_dir = image_path / \"train\"\n",
    "test_dir = image_path / \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcd7f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we set our image size and transform our images before puting them through \n",
    "#the dataloaders\n",
    "IMG_SIZE = 224\n",
    "\n",
    "#Create transform pipeline\n",
    "manual_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "print(f'Image transformer created: {manual_transforms}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d03d7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vit states they used batch size of 4096 and until i switch to running on my PC where I \n",
    "# have a GPU that can handle that I will be using a batch size of 24\n",
    "BATCH_SIZE = 24 if device == \"cpu\" else 4096\n",
    "\n",
    "#Create data loaders\n",
    "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(\n",
    "    train_dir=train_dir,\n",
    "    test_dir=test_dir,\n",
    "    transform=manual_transforms, #use previously defined transforms\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "train_dataloader, test_dataloader, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875eb2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets see if the dataloaders worked correctly by loading an image \n",
    "# first grab a batch of images from the train set \n",
    "image_batch, label_batch = next(iter(train_dataloader))\n",
    "\n",
    "# get a single image from the batch \n",
    "image, label = image_batch[0], label_batch[0]\n",
    "\n",
    "#view  the objects\n",
    "image.shape, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12758af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#that didn't really visualize it but we can see the size and the the associaate label tensor \n",
    "# so lets plot it w/matplotlib\n",
    "plt.imshow(image.permute(1, 2, 0)) #rearrange image dimensions to suit matplotlib [color_channels, height, width] -> [height, width, color_channels]\n",
    "plt.title(class_names[label])\n",
    "plt.axis(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6925c63",
   "metadata": {},
   "source": [
    "mmmm good looking pizza, or steak, or sushi\n",
    "\n",
    "## now we are ready to actually replecate the paper "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a768a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We start by calculating the patch embedding input and output shapes\n",
    "# our training resolution is 224 x 224 (H x W) \n",
    "height = 224\n",
    "width = 224 \n",
    "color_channels = 3 # C \n",
    "patch_size = 16 # P - taken from column ViT-B/16 from table 5 in the ViT paper \n",
    "\n",
    "# calculate N (number of patches) \n",
    "number_of_patches = int((height * width) / patch_size**2)\n",
    "print(f\"Number of patches N w/ image height (H = {height}), width (W = {width}) and patch size (P = {patch_size}) is (N = {number_of_patches})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3edb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOw lets replicate the input and output shapes of the patch embedding layer \n",
    "# Input: Image starts as 2D w/size (H x W x C)\n",
    "embedding_layer_input_shape = (height, width, color_channels)\n",
    "\n",
    "# Output: Image gets converted to a sequence of flattened 2D patches w/size (N x (P^2 dot C))\n",
    "embedding_layer_output_shape = (number_of_patches, patch_size**2 * color_channels)\n",
    "print(f\"Input Shape (single 2D image): {embedding_layer_input_shape}\")\n",
    "print(f\"Output Shape (single 2d Image flattened into patches): {embedding_layer_output_shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e141d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets convert an image into patches\n",
    "#change Image shape to be compatible w/matplotlib (color_channels, height, width) -> (height, width, color_channels)\n",
    "image_permuted = image.permute(1,2,0)\n",
    "\n",
    "#index to plot the top row of patched pixels\n",
    "patch_size = 16\n",
    "plt.figure(figsize=(patch_size, patch_size))\n",
    "plt.imshow(image_permuted[:patch_size, :, :])\n",
    "#this should show the top row of patched pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0bf46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now lets see a single patch \n",
    "plt.figure(figsize=(patch_size, patch_size))\n",
    "plt.imshow(image_permuted[:patch_size, :patch_size, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396400d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we can turn this into individual patches \n",
    "#Setup hyperparameters and make sure image size and patch size are compatible \n",
    "img_size = 224\n",
    "# patch_size = 16 #Don't redefine instead reuse\n",
    "num_patches = img_size / patch_size \n",
    "assert img_size%patch_size == 0, \"Image size must be divisible by patch size\"\n",
    "print(f\"Number of patches per row: {num_patches} \\n Patch size: {patch_size} pixels x {patch_size} pixels\")\n",
    "\n",
    "#Create series of subplots \n",
    "fig, axs = plt.subplots(\n",
    "    nrows=1,\n",
    "    ncols=img_size//patch_size, # One column per patch\n",
    "    figsize=(num_patches, num_patches),\n",
    "    sharex=True,\n",
    "    sharey=True\n",
    ")\n",
    "\n",
    "#Iterate through number of patches in the top row \n",
    "for i, patch in enumerate(range(0, img_size, patch_size)):\n",
    "    axs[i].imshow(image_permuted[:patch_size, patch:patch+patch_size, :]) # Keep height index constant, alter width index\n",
    "    axs[i].set_xlabel(i+1) #Set label for patch number\n",
    "    axs[i].set_xticks([])\n",
    "    axs[i].set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b84b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now how do we expand this for the full image? While keeping the correct hyperparameters, img_size and patch_size\n",
    "#img_size = 224\n",
    "#patch_size = 16 \n",
    "#num_patches = img_size/patch_size\n",
    "assert img_size % patch_size == 0, \"Image size must be divisible by patch size\"\n",
    "print(f\"Number of patches per row: {num_patches}\\\n",
    "        \\nNumber of patches per column: {num_patches}\\\n",
    "        \\nTotal patches: {num_patches*num_patches}\\\n",
    "        \\nPatch size: {patch_size} pixels x {patch_size} pixels\")\n",
    "    \n",
    "# again create series of subplots\n",
    "fig, axs = plt.subplots(\n",
    "    nrows=img_size//patch_size, # Need as int not float\n",
    "    ncols=img_size//patch_size,\n",
    "    figsize=(num_patches, num_patches),\n",
    "    sharex=True,\n",
    "    sharey=True\n",
    ")\n",
    "\n",
    "#loop through height and width this time\n",
    "for i, patch_height in enumerate(range(0, img_size, patch_size)): #iterate through height\n",
    "    for j, patch_width in enumerate(range(0, img_size, patch_size)): #iterate through width \n",
    "        #Plot permuted image patch \n",
    "        axs[i,j].imshow(image_permuted[\n",
    "            patch_height:patch_height+patch_size, # iterate height\n",
    "            patch_width:patch_width+patch_size, #iterate width\n",
    "            :]) # Get all color_channel\n",
    "        axs[i,j].set_ylabel(i+1, rotation='horizontal', horizontalalignment='right', verticalalignment='center')\n",
    "        axs[i,j].set_xlabel(j+1)\n",
    "        axs[i,j].set_xticks([])\n",
    "        axs[i,j].set_yticks([])\n",
    "        axs[i,j].label_outer()\n",
    "\n",
    "#Set super title for overall plot \n",
    "fig.suptitle(f\"{class_names[label]} -> Patchified Bitches\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20671861",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
